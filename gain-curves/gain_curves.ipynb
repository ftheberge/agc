{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc, average_precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "from gain_curves import * ## our functions stored in gain-curves.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af66ba",
   "metadata": {},
   "source": [
    "# Random example\n",
    "\n",
    "- We use this dataset throughout\n",
    "- **N = 20,000** with 5% positive labels\n",
    "- Bimodal distribution for the positive case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "## labels\n",
    "N = 20000\n",
    "N_pos = 1000\n",
    "labels = np.concatenate((np.repeat(1,N_pos),np.repeat(0,N-N_pos)))\n",
    "\n",
    "## scores\n",
    "scores = np.concatenate((np.random.normal(.75,.1,N_pos//5),np.random.normal(.45,.15,N_pos-N_pos//5),\n",
    "                         np.random.normal(.4,.15,N-N_pos)))\n",
    "\n",
    "## clumping\n",
    "scores = [min(1,i) for i in scores]\n",
    "scores = [max(0,i) for i in scores]\n",
    "\n",
    "## plot\n",
    "D = pd.DataFrame()\n",
    "D['labels']=labels\n",
    "D['scores']=scores\n",
    "ax = sns.violinplot(x=\"labels\", y=\"scores\", data=D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b9849",
   "metadata": {},
   "source": [
    "# ROC and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50069e",
   "metadata": {},
   "source": [
    "- define TP: number of true positives, FP: false positives, TN: true negatives, FN: false negatives\n",
    "- TruePositiveRate: TPR = TP/(TP+FN)\n",
    "- FalsePositiveRate: FPR = FP/(FP+TN)\n",
    "- ROC curve: plot TPR vs FPR for all possible thresholds\n",
    "- AUC is the area under the ROC curve via trapezoidal rule\n",
    "- For random ordering, expected AUC is R(AUC) = 0.5.\n",
    "- Maximum value for AUC is: M(AUC)=1\n",
    "- interpretation: AUC = Pr(score of random positive case > score of random negative case)\n",
    "- Thus, one can easily approximate AUC even for huge datasets by sampling (with replacement) from positive cases, sampling (with replacement) negative cases and compare the samples.\n",
    "\n",
    "We also define the **normalized AUC** as **AUC' = (AUC - R(AUC))/(M(AUC) - R(AUC)) = 2*AUC - 1**\n",
    "so AUC' is the proportion of potential improvement over random that we achieved; this can be negative is we do worse than random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AUC\n",
    "fpr, tpr, thresholds = roc_curve(np.array(labels), np.array(scores), pos_label=1)\n",
    "AUC = roc_auc_score(np.array(labels), np.array(scores))\n",
    "print('AUC=',AUC,'AUC\\'=',(AUC-.5)/.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot ROC\n",
    "## AUC = \"area under red curve\"\n",
    "## AUC'= (\"area under red curve\"-\"area under black curve\")/(\"area under blue curve\"-\"area under black curve\")\n",
    "plt.plot(fpr,tpr,color='red')\n",
    "plt.plot([0,1],[0,1],color='black')\n",
    "plt.plot([0,0,1],[0,1,1],color='blue')\n",
    "plt.xlabel('FPR',fontsize=14)\n",
    "plt.ylabel('TPR',fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3716cdab",
   "metadata": {},
   "source": [
    "# Precision-recall curve\n",
    "\n",
    "* recall = TP/(TP+FN)\n",
    "* precision = TP/(TP+FP)\n",
    "* we plot precision vs recall; result can be summarized via area under the curve using the trapeziodal rule, or the (similar) average precision (AP)\n",
    "* Maximum value is 1, expected value under random classifier is the proportion of positive label points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac158e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Precision-recall\n",
    "precision, recall, _ = precision_recall_curve(np.array(labels), np.array(scores), pos_label=1)\n",
    "print('Area under curve:',auc(recall, precision))\n",
    "print('Average precision:',average_precision_score(np.array(labels), np.array(scores), pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot PR curve\n",
    "plt.plot(recall,precision,color='red')\n",
    "plt.xlabel('Recall',fontsize=14)\n",
    "plt.ylabel('Precision',fontsize=14);\n",
    "plt.plot([0,1],[N_pos/N,N_pos/N],color='black')\n",
    "plt.plot([0,0,1],[0,1,1],color='blue');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7904fe4e",
   "metadata": {},
   "source": [
    "# Gain curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b037ab",
   "metadata": {},
   "source": [
    "For AUC or AP, we consider the entire curve. In practice, we may be very restricted in terms of the number of points we can look at, so we want as many positive cases to score high, say in the **top-k** or the **top (100*q)%**.\n",
    "\n",
    "We can look at the precision for the top-k, but this neglects the ordering. One alternative is to look at **gain** curves. Let N be the total number of data points. We plot a gain curve by plotting: \n",
    "\n",
    "- for the x-axis: (TP+FP)/N, the proportion of points at or above the threshold, and\n",
    "- for the y-axis: TPR.\n",
    "\n",
    "Thus, is is simple to **truncate** a gain curve by looking only at the **top (100*q)%** scoring points as we show below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134a6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot gain curve as well as max and (expected) random curves\n",
    "top, tpr, _ = gain_curve(y_true=labels, y_score=scores, pos_label=1, truncate=1)\n",
    "plt.plot(top,tpr,'red')\n",
    "plt.plot([0,1],[0,1],color='black') ## random\n",
    "r = N_pos/N ## proportion of positives overall\n",
    "plt.plot([0,r,1],[0,1,1],color='blue'); ## max\n",
    "plt.xlabel('Proportion of top scoring points',fontsize=14)\n",
    "plt.ylabel('TPR',fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12452bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## partial gain curve - truncate at 10%\n",
    "trunc = .1\n",
    "top, tpr, _ = gain_curve(y_true=labels, y_score=scores, pos_label=1, truncate=trunc)\n",
    "plt.plot(top,tpr,'red')\n",
    "plt.plot([0,trunc],[0,trunc],color='black') ## random\n",
    "r = N_pos/N ## proportion of positives overall\n",
    "if r <= trunc:\n",
    "    plt.plot([0,r,trunc],[0,1,1],color='blue') ## max\n",
    "else:\n",
    "    plt.plot([0,trunc],[0,N*trunc/N_pos],color='blue');\n",
    "plt.xlabel('Proportion of top scoring points',fontsize=14)\n",
    "plt.ylabel('TPR',fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda046d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## partial gain curve - truncate at 1%\n",
    "trunc = .01\n",
    "top, tpr, _ = gain_curve(y_true=labels, y_score=scores, pos_label=1, truncate=trunc)\n",
    "plt.plot(top,tpr,'red')\n",
    "plt.plot([0,trunc],[0,trunc],color='black') ## random\n",
    "r = N_pos/N ## proportion of positives overall\n",
    "if r <= trunc:\n",
    "    plt.plot([0,r,trunc],[0,1,1],color='blue') ## max\n",
    "else:\n",
    "    plt.plot([0,trunc],[0,N*trunc/N_pos],color='blue');\n",
    "plt.xlabel('Proportion of top scoring points',fontsize=14)\n",
    "plt.ylabel('TPR',fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcfa8a4",
   "metadata": {},
   "source": [
    "# AGC - area under the gain curve\n",
    "\n",
    "Everything so far is well known. We now introduce our new results.\n",
    "\n",
    "Consider the normalized area under the gain curve\n",
    "\n",
    "**AGC'(q) = (AGC(q) - R(AGC(q)))/(M(AGC(q)) - R(AGC(q)))**\n",
    "\n",
    "with the option of **truncating** the curve to the **top-(100q)%** scoring points.\n",
    "\n",
    "We wrote two new functions to compute AGC':\n",
    "- AGC where parameter truncate = **q**\n",
    "    - we can also pass an integer q>1 in which case we consider the top-q points\n",
    "- AGC_sample: approximation of AGC, useful for huge graphs, with two extra parameters: \n",
    "    - sample (proportion of points to sample)\n",
    "    - quantiles (number of quantiles to use for binning)\n",
    "\n",
    "**Proposition** (proof in our paper): AGC'(1) = AUC', i.e. when no truncation is done.\n",
    "\n",
    "Finaly, unlike AUC, the maximum value M(AGC)<1, so for the un-normalized area, we consider AGC/M(AGC) so that a perfect ordering yields a value of 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871e54b",
   "metadata": {},
   "source": [
    "## Truncated gain function and version with sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AGC':\",gain_agc_score(y_true=labels, y_score=scores, pos_label=1),\n",
    "'approx_1:',gain_agc_approximate(y_true=labels, y_score=scores, sample=1, quantiles=200, pos_label=1),\n",
    "'approx_2:',gain_agc_approximate(y_true=labels, y_score=scores, sample=.5, quantiles=100, pos_label=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recall tht AGC' = AUC' when no truncation is done, let's check\n",
    "(AUC-.5)/.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162dbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## looking at distribution for several approximations\n",
    "g = []\n",
    "for i in range(30):\n",
    "    g.append(gain_agc_approximate(y_true=labels, y_score=scores, sample=.5, quantiles=100, pos_label=1))\n",
    "plt.boxplot(g,showfliers=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGC with truncation to top 10% and approximations\n",
    "print(\"AGC':\",gain_agc_score(y_true=labels, y_score=scores, pos_label=1, truncate=.1),\n",
    "'approx_1:',gain_agc_approximate(y_true=labels, y_score=scores, sample=1, quantiles=200, pos_label=1, truncate=.1),\n",
    "'approx_2:',gain_agc_approximate(y_true=labels, y_score=scores, sample=.5, quantiles=100, pos_label=1, truncate=.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab8990",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGC with truncation to top 2000 and approximations\n",
    "print(\"AGC':\",gain_agc_score(y_true=labels, y_score=scores, pos_label=1, truncate=2000),\n",
    "'approx_1:',gain_agc_approximate(y_true=labels, y_score=scores, sample=1, quantiles=200, pos_label=1, truncate=2000),\n",
    "'approx_2:',gain_agc_approximate(y_true=labels, y_score=scores, sample=.5, quantiles=100, pos_label=1, truncate=2000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGC with truncation to top 1% (dataset too small to sample here)\n",
    "print(\"AGC':\",gain_agc_score(y_true=labels, y_score=scores, pos_label=1, truncate=.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AGC with truncation to top 200 (dataset too small to sample here)\n",
    "print(\"AGC':\",gain_agc_score(y_true=labels, y_score=scores, pos_label=1, truncate=200))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c9848",
   "metadata": {},
   "source": [
    "## Weighted dataset\n",
    "\n",
    "- we add random weights to all datapoints for testing\n",
    "- default (unweighted) correponds to all weights == 1\n",
    "- we wrote a function to compute AUC with weights, as this is not an option in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate random weights \n",
    "W = 1+9*np.random.exponential(5,size=len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f01e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## weighted AUC\n",
    "AUC = roc_auc_score(np.array(labels), np.array(scores), sample_weight=np.array(W))\n",
    "print('AUC=',AUC,'AUC\\'=',(AUC-.5)/.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc6a8e",
   "metadata": {},
   "source": [
    "### Sampling approximation to AUC\n",
    "\n",
    "- AUC = Pr(score for weighted sampled positive point > score for weighted sampled negative point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d46f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample size\n",
    "ss = 2000\n",
    "## recall - first N_pos points are positive\n",
    "w_pos = W[:N_pos]/np.sum(W[:N_pos])\n",
    "w_neg = W[N_pos:]/np.sum(W[N_pos:])\n",
    "s_pos = [scores[i] for i in np.random.choice(N_pos,size=ss,replace=True,p=w_pos)]\n",
    "s_neg = [scores[i] for i in N_pos+np.random.choice(N-N_pos,size=ss,replace=True,p=w_neg)]\n",
    "print('AUC approximation:',sum(np.array(s_pos)>np.array(s_neg))/ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcdcb33",
   "metadata": {},
   "source": [
    "### AGC with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145638b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## weighted AGC\n",
    "print('AGC = ',gain_agc_score(labels, scores, sample_weight=W, normalized=False))\n",
    "## weighted AGC' (this = AUC')\n",
    "print(\"AGC'= \",gain_agc_score(labels, scores, sample_weight=W, normalized=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e5207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## weighted AND truncated AGC'\n",
    "print(\"AGC'= \",gain_agc_score(labels, scores, sample_weight=W, truncate=1000))\n",
    "\n",
    "## Approximation for AGC'\n",
    "print(\"AGC'(approximation):\",gain_agc_approximate(labels, scores, sample_weight=W, truncate=1000, sample=.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8372ff",
   "metadata": {},
   "source": [
    "## Timings - AGC vs sampling\n",
    "\n",
    "We look at the impact of sample size on the speed and accuracy.\n",
    "\n",
    "We also look at the number of quantiles, which has much less impact, unless we \n",
    "ask for a very large number. The issue there is with the np.quantile() function, \n",
    "which can get very slow with thousands of quantiles. We got even slower results with the pandas version.\n",
    "One way to speed up a little is to use the option interpolation='nearest' instead of the default (linear).\n",
    "We added this as an option in the function call.\n",
    "\n",
    "However, we found that such a large number of quantiles is not necessary in the tests we ran.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d48764",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first we vary the sample size\n",
    "import time\n",
    "REP = 30\n",
    "start = time.time()\n",
    "for i in range(REP):\n",
    "    gain_agc_score(labels, scores)\n",
    "end = time.time()\n",
    "T = end-start\n",
    "A = gain_agc_score(labels, scores)\n",
    "\n",
    "t = []\n",
    "a = []\n",
    "S = [.1,.2,.3,.4,.5,.6,.7,.8,.9,1]\n",
    "for s in S:\n",
    "    x = 0\n",
    "    start = time.time()\n",
    "    for i in range(REP):\n",
    "        x += np.abs(gain_agc_approximate(labels, scores, sample=s, quantiles=100)-A)/A\n",
    "    end = time.time()\n",
    "    t.append( 100*(end - start)/T )\n",
    "    a.append(100*x/REP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(S,t,'o-',label='timing (% vs full)' )\n",
    "plt.plot(S,a,'o-',label='error (% vs full)')\n",
    "M = max(a+t)+5\n",
    "plt.ylim((-5,M))\n",
    "plt.ylabel('% vs full AGC',fontsize=14)\n",
    "plt.xlabel('sampling proportion',fontsize=14)\n",
    "plt.title('Results with 100 quantiles',fontsize=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ef74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now vary number of quantiles, sampling 50%\n",
    "REP = 30\n",
    "start = time.time()\n",
    "for i in range(REP):\n",
    "    gain_agc_score(labels, scores)\n",
    "end = time.time()\n",
    "T = end-start\n",
    "A = gain_agc_score(labels, scores)\n",
    "\n",
    "t = []\n",
    "a = []\n",
    "Q = np.arange(5,301,20)\n",
    "for q in Q:\n",
    "    x = 0\n",
    "    start = time.time()\n",
    "    for i in range(REP):\n",
    "        x += np.abs(gain_agc_approximate(labels, scores, sample=.5, quantiles=q)-A)/A\n",
    "    end = time.time()\n",
    "    t.append( 100*(end - start)/T )\n",
    "    a.append( 100*x/REP )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ff597",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Q,t,'.-',label='timing (% vs full)' )\n",
    "plt.plot(Q,a,'.-',label='error (% vs full)')\n",
    "M = max(a+t)+5\n",
    "m = min(a+t)-5\n",
    "plt.ylim((m,M))\n",
    "plt.ylabel('% vs full AGC',fontsize=14)\n",
    "plt.xlabel('number of quantiles',fontsize=14)\n",
    "plt.title('Results with 50% sampling',fontsize=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c114902",
   "metadata": {},
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f gain_agc_approximate gain_agc_approximate(labels, scores, sample=.7, quantiles=4000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphmining",
   "language": "python",
   "name": "graphmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
